{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d8031fb",
   "metadata": {},
   "source": [
    "# Training a Custom Tokenizer for StackOverflow QA Pairs (C Language)\n",
    "\n",
    "This notebook demonstrates how to train your own tokenizer using Hugging Face's Transformers and Tokenizers libraries. Custom tokenizers are useful when you want your language model to better understand the specific vocabulary and structure of your dataset. Here, we focus on StackOverflow QA pairs related to the C programming language.\n",
    "\n",
    "We'll explore different tokenization algorithms and show how to build and train them step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5092b3b",
   "metadata": {},
   "source": [
    "## Why Train Your Own Tokenizer?\n",
    "\n",
    "Most transformer models use subword tokenization algorithms, which need to be trained to recognize common patterns in your data. By training a tokenizer on your own dataset, you help your model understand domain-specific words and phrases, leading to better results when training or fine-tuning language models.\n",
    "\n",
    "For more details, you can check out the Hugging Face course <a href=\"https://huggingface.co/learn/llm-course/en/chapter2/4\">chapter</a> on tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799203b1",
   "metadata": {},
   "source": [
    "### Prepare with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "12a81022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 40649\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Mxode/StackOverflow-QA-C-Language-40k\", trust_remote_code=True)    \n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aedc578e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': ['\\nConsider this implementation ofstrtok()in C\\n\\n```\\nchar *pt;\\npt = strtok(line, \":\");\\nif (pt != NULL)\\n{\\n    pt = strtok(NULL, \":\");\\n}\\n```\\n\\nwhy doesn\\'tpthave to be explicitly allocated memory? Likept[128]orpt = malloc(...)? I would have thought the above implementation would segfault. Do I have to worry about deallocation?\\n', '\\nI am trying to extract two last characters from achararray and has been unable to do so. The array will be given to me and I don\\'t have control over it. I only know the lastnpositions of the array are digits. In the following casen=2:\\n\\n```\\nchar c[5] = \"xyz45\"\\nchar d[2];\\nd[0] = c[3];\\nd[1] = c[4];\\nint e = atoi(d);\\n```\\n\\nClearly the value oferequired is45. Any way to solve this? (The above approach is a representative way about how one might go about doing this in python. I am looking for an elegant way to do this.)\\n', '\\nI am trying to figure out this issue:\\nI tried to run this two easy codes\\n\\n```\\nint main(void) {\\n    while(1) {\\n       printf(\"Do nothing\\\\n\");\\n    }\\n   return 0;\\n}\\n```\\n\\nWhen I execute it my memory RAM runs out.\\nThen I tried this variation:\\n\\n```\\nint main(void) {\\n    while(1) {\\n       // do nothing\\n    }\\n   return 0;\\n}\\n```\\n\\nAnd on that case my code runs without running out RAM.\\nMy question is: why does it happen? Doesprintfoccupied memory or maybe I am overloadingstdout?Thanks!\\n', '\\nI understand that normally arrays are unassignable. However I recently came across this\\n\\n```\\nstruct S {\\n    int arr[6];\\n};\\n```\\n\\nAnd this lets me do something like this\\n\\n```\\nstruct S a = {1, 2, 3, 4, 5, 6};\\nstruct S b;\\nb = a; // b.arr is now a deep clone of a.arr?\\n```\\n\\nThis seems odd because I would have thought such assignment would result in a shallow copy being stored in b, as only the address of the first element of a.arr would be copied?\\n', '\\nI know thatprintf(user_input)is dangerous, but what aboutprintf(\"%s\", user_input)? Is this generally safe as longuser_inputis NUL terminated?\\n'], 'answer': ['\\nlinehas to reference modifiablechararray and moststrtokimplementations are using this memory.\\n\\nIt is the reason why you do not have to provide any additional memory for this operation.\\n\\nRemember thatlinewill be modified (destroyed) during this operation.\\n\\nptwill hold (if notNULL) the reference to one of the elements of the array referenced byline\\n', '\\nI only know the lastnpositions of the array are digits.\\n\\nA simple loop suffices (assuming no overflow insum):\\n\\n```\\nchar c[] = ... \\nint len = ...  // length of the array\\nint n = ...   \\n\\nint sum = 0;\\nfor (int i = len - n; i < len; i++) {\\n  sum = sum * 10 + (c[i] - \\'0\\');\\n}\\n  \\nprintf(\"%d\\\\n\", sum);\\n```\\n', \"\\nIf the terminal that is running out of memory, then yes, the terminal isn't clearing the stdout properly.\\n\\nIf it's the program itself running out of memory, then i don't know actually.\\n\", \"\\nArrays are strange in C. They're distinct from pointers, but many operations on them make them implicitlydecayinto pointers, which can misguide you to think they the same.\\n\\nThis array is stored inline into eachstruct Sinstance. Upon assignment, its copied in its entirety, just like any otherintmembers that might be inside the struct instance. There's no shallow-copy vs deep-copy distinction here, because there is no out-of-line pointer-referenced data to be worried about.\\n\", '\\nI know thatprintf(user_input)is dangerous, but what aboutprintf(\"%s\", user_input)? Is this generally safe?\\n\\nThe latter is among the replacements commonly recommended for the former.  It resolvesthe issue that makesprintf(user_input)particularlydangerous.\\n\\nThere remain more general issues such as what happens ifuser_inputis not a pointer to a null-terminated string, or if the string contains characters that elicit special behavior from the output device, or if the standard output stream has been closed, or maybe other things.\\n\\nI\\'m not sure \"generally safe\" is a good description of all that, but perhaps it is indeed what you meant.\\n']}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0dda326d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consider this implementation ofstrtok()in C\n",
      "\n",
      "```\n",
      "char *pt;\n",
      "pt = strtok(line, \":\");\n",
      "if (pt != NULL)\n",
      "{\n",
      "    pt = strtok(NULL, \":\");\n",
      "}\n",
      "```\n",
      "\n",
      "why doesn'tpthave to be explicitly allocated memory? Likept[128]orpt = malloc(...)? I would have thought the above implementation would segfault. Do I have to worry about deallocation?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0]['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "86cf8ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "linehas to reference modifiablechararray and moststrtokimplementations are using this memory.\n",
      "\n",
      "It is the reason why you do not have to provide any additional memory for this operation.\n",
      "\n",
      "Remember thatlinewill be modified (destroyed) during this operation.\n",
      "\n",
      "ptwill hold (if notNULL) the reference to one of the elements of the array referenced byline\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0]['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0eb87c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c3f080",
   "metadata": {},
   "source": [
    "### Efficient Data Loading for Training\n",
    "\n",
    "When working with large datasets, it's best to process data in batches rather than loading everything into memory. We use a Python generator to yield batches of texts, which makes training more memory-efficient and scalable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a3876fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "def batch_generator():\n",
    "    for i in range(0, len(dataset), batch_size):\n",
    "        for k in ['question', 'answer']:\n",
    "            yield dataset[k][i: i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fd96f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d99a7",
   "metadata": {},
   "source": [
    "### Training a Tokenizer Based on an Existing Model\n",
    "\n",
    "If you want your tokenizer to use the same algorithm and parameters as a popular model (like Llama or GPT-2), you can start from that model and retrain its tokenizer on your own data. This is a quick way to adapt a proven tokenization strategy to your specific domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c246621a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3ff26d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad69c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokenizer = tokenizer.train_new_from_iterator(batch_generator(), vocab_size=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "73105b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 204, 10, 8, 5079, 100, 2220, 56, 10513, 434, 5, 2, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(new_tokenizer('This is a demo string copied from stackoverflow! üòä'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2f8e021e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "30725b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wich': 17351,\n",
       " '‚äï': 29716,\n",
       " '‚ñÅpclose(fp);\\n': 24087,\n",
       " '‚ñÅarg2': 10136,\n",
       " 'fnct': 22572,\n",
       " 'RHS': 15949,\n",
       " 'BOOL': 10450,\n",
       " '‚ñÅ<string.h>\\n': 2230,\n",
       " ');\\n```\\n\\nI': 1181,\n",
       " '‚ñÅGET_RED_TEXT(': 27571,\n",
       " '-E': 11604,\n",
       " \"getenv('PWD')\": 23793,\n",
       " '‚ñÅdecides': 12434,\n",
       " 'Copie': 24988,\n",
       " '‚ñÅwant': 54,\n",
       " '‚ñÅencoder': 19737,\n",
       " '‚ñÅrhs': 22473,\n",
       " 'spaces': 13497,\n",
       " 'immediately': 15186,\n",
       " '‚ñÅmessages': 1764,\n",
       " ';\\nstruct': 3046,\n",
       " 'Bytes': 6269,\n",
       " 'truct/union/enum': 28798,\n",
       " 'room_dim': 22322,\n",
       " '?\\n\\nP.S.': 14381,\n",
       " '‚ñÅ__cplusplus\\n': 12025,\n",
       " '‚ñÅmain.o': 8315,\n",
       " '‚ñÅbelow.': 5913,\n",
       " '13,': 12834,\n",
       " 'introspection': 22213,\n",
       " '‚ñÅthread-local': 20888,\n",
       " '‚ñÅ<string.h>\\n\\nint': 3303,\n",
       " '‚ñÅ<errno.h>\\n': 12415,\n",
       " '‚ñÅstrdup(': 8091,\n",
       " 'Conversely': 24713,\n",
       " 'g_signal_': 23016,\n",
       " '‚ñÅbased': 944,\n",
       " 'STM32Cube': 25120,\n",
       " ':\\n\\n```\\nchar*': 3260,\n",
       " '1)\\n{\\n': 11050,\n",
       " 'feof(fp)': 24271,\n",
       " ',i,j,k,': 24124,\n",
       " ';j++)\\n': 7409,\n",
       " 'hal': 13810,\n",
       " '0x4': 17077,\n",
       " '(4,': 14593,\n",
       " 'PCRE': 14471,\n",
       " '‚ñÅErlang/Elixir': 28266,\n",
       " '‚ñÅfive': 6741,\n",
       " \"‚ñÅ'one\": 15096,\n",
       " '‚ñÅarrays': 635,\n",
       " '‚ñÅ{0};\\n\\n': 15414,\n",
       " 'Eigen': 19225,\n",
       " 'Var': 4154,\n",
       " '‚ñÅexample.': 6278,\n",
       " '‚ñÅCGI': 9262,\n",
       " 'et': 2440,\n",
       " 'scanning': 21112,\n",
       " '‚ñÅpredecessor': 17970,\n",
       " '‚ñÅdiff': 6421,\n",
       " \"‚ñÅthread's\": 14512,\n",
       " 'MONOTONIC': 25117,\n",
       " '‚ñÅteach': 12500,\n",
       " 'thread_': 7779,\n",
       " '4.1': 6254,\n",
       " 'Red': 6969,\n",
       " 'post-': 18200,\n",
       " \"%ld',\": 14574,\n",
       " 'Po': 8835,\n",
       " '‚ñÅenumerate': 9767,\n",
       " '‚ñÅfoo()\\n{\\n': 11939,\n",
       " '{10,20,30,40,50}': 26832,\n",
       " '‚ñÅInterface': 8319,\n",
       " '(a': 1736,\n",
       " 'displayThrFxn': 29011,\n",
       " '‚ñÅcount=0;\\n': 19122,\n",
       " '1.0': 3989,\n",
       " 'note:': 15545,\n",
       " '‚ñÅBook': 8982,\n",
       " 'PRIszu': 23291,\n",
       " 'r);\\n': 9080,\n",
       " 'spiral': 19605,\n",
       " \"scanf('%c\": 13133,\n",
       " '‚ñÅ&number': 8861,\n",
       " '‚ñÅdev': 4418,\n",
       " 'fork': 3356,\n",
       " \"\\\\'\": 2478,\n",
       " 'Tried': 13664,\n",
       " '‚ñÅLine': 6871,\n",
       " 'my_ADT.c': 21285,\n",
       " 'client.c': 16691,\n",
       " '‚ñÅwarning.\\n': 11686,\n",
       " 'CMAKE_C_FLAGS': 21568,\n",
       " 'synonymous': 22934,\n",
       " '-string': 12691,\n",
       " \"‚ñÅ'r');\\n\": 3524,\n",
       " '{return': 14519,\n",
       " 'Names': 13394,\n",
       " \"printf('World')\": 22120,\n",
       " 'de38cf:000391716': 29608,\n",
       " 'Hook': 15284,\n",
       " '‚ñÅrenaming': 16872,\n",
       " '‚ñÅreceived': 2207,\n",
       " '%20': 7964,\n",
       " '‚ñÅexpires': 23373,\n",
       " '‚ñÅgreatly': 3311,\n",
       " '\\n\\nlike': 14855,\n",
       " '(ispunct(': 28577,\n",
       " '‚ñÅsendfile': 16401,\n",
       " '‚ñÅlevels': 10416,\n",
       " '2686696': 26624,\n",
       " '‚ñÅFurthermore,': 12243,\n",
       " 'utils': 10207,\n",
       " 'sh:': 15707,\n",
       " '‚ñÅ}\\n\\n': 616,\n",
       " '‚ñÅhamming_string': 24183,\n",
       " '‚ñÅprintargs(': 23573,\n",
       " '‚ñÅipv6': 11257,\n",
       " '‚ñÅnoticed': 2723,\n",
       " '(20)': 18294,\n",
       " 'st_mtime': 13916,\n",
       " '‚ñÅregion': 3797,\n",
       " '‚ñÅredesign': 21895,\n",
       " '‚ñÅtrying': 135,\n",
       " '‚ñÅper': 1083,\n",
       " '%Y-%m-%d': 23134,\n",
       " 'slope': 18823,\n",
       " '‚ñÅc=a+b;\\n': 21377,\n",
       " 'Compiling': 7337,\n",
       " 'con': 5365,\n",
       " '\\n```\\n\\nOR\\n\\n```\\n': 21125,\n",
       " 'departmentList': 25214,\n",
       " '‚ñÅstrings.\\n': 13013,\n",
       " '‚ñÅtransaction': 15587,\n",
       " 'OCESS_DUP_HANDLE': 25885,\n",
       " '‚ñÅj--;\\n': 20151,\n",
       " '‚ñÅout-of-': 14759,\n",
       " 'GtkBox': 22511,\n",
       " '‚ñÅ2': 174,\n",
       " \"'¬¶¬¶¬¶-++¬¶-+++---+\": 28294,\n",
       " '‚ñÅDEBUG': 5398,\n",
       " '‚ñÅfwrite': 8960,\n",
       " '‚ñÅ8,': 5194,\n",
       " \"\\n\\nI've\": 11291,\n",
       " 'index.php': 14460,\n",
       " '->d_name);\\n': 18623,\n",
       " '.\\n\\nWith': 4569,\n",
       " '\\nUnder': 11435,\n",
       " 'Google': 7578,\n",
       " 'ERE': 20292,\n",
       " 'bulb': 21417,\n",
       " '‚ñÅexclusive': 14395,\n",
       " 'sizeof(int)*': 7313,\n",
       " 'Motif': 21857,\n",
       " 'ubygems': 24946,\n",
       " '‚ñÅstarted': 1372,\n",
       " '‚ñÅexpansion': 3926,\n",
       " '<glib.h>\\n': 25496,\n",
       " '(*x)': 13040,\n",
       " 'ServerAmount': 22769,\n",
       " '‚ñÅj=0;j<': 21227,\n",
       " 'euid': 19331,\n",
       " '‚ñÅprogramming.': 4768,\n",
       " 'eflate_copyright': 28744,\n",
       " 'handle_request(': 24867,\n",
       " '‚ñÅi--){\\n': 17783,\n",
       " 'Definitely': 21733,\n",
       " 'Widget': 15892,\n",
       " '‚ñÅfill': 2149,\n",
       " '‚ñÅdescribing': 11656,\n",
       " \"fscanf(m,'%d',\": 23274,\n",
       " '‚ñÅva_start(a': 18925,\n",
       " '‚ñÅpreferable': 8943,\n",
       " 'plural[len-2]=': 28673,\n",
       " '‚ñÅeasy': 1001,\n",
       " '‚ñÅbuffers': 3918,\n",
       " 'blog': 16343,\n",
       " \"‚ñÅ'';\\n```\\n\\n\": 19520,\n",
       " 'derivative': 14148,\n",
       " '‚ñÅpreceding': 11885,\n",
       " '‚ñÅhav': 21213,\n",
       " '‚ñÅdisregard': 26802,\n",
       " '[i+1]': 7452,\n",
       " 'strlen(argv[1])': 15956,\n",
       " 'useppe/struct.c:': 25992,\n",
       " 'locked[0][j]);': 26270,\n",
       " '‚ñÅresult': 211,\n",
       " '‚ñÅoperation.': 11105,\n",
       " 'strlen(str1)': 19102,\n",
       " \"1',\": 5855,\n",
       " '¬ß6.8.4': 27290,\n",
       " 'Cheers\\n': 22608,\n",
       " 'msgflg': 25485,\n",
       " '‚ñÅdisabling': 16225,\n",
       " '[40]': 13316,\n",
       " 'Expected': 8343,\n",
       " '\\n```\\n\\nthe': 5235,\n",
       " \"‚ñÅtext/plain\\\\n\\\\n'\": 27129,\n",
       " 'array[N]={2-N};\\n': 28221,\n",
       " 'stmt_free_result': 25934,\n",
       " 'CC=gcc\\nCFLAGS=': 24987,\n",
       " '‚ñÅ(t': 9618,\n",
       " '‚ñÅkeyboard': 2824,\n",
       " '(x,': 4303,\n",
       " '„Åä': 21239,\n",
       " 'Attach': 17630,\n",
       " '‚ñÅcontrols': 11780,\n",
       " 'PostRedisplay()': 27145,\n",
       " 'cust': 21562,\n",
       " '‚ñÅwaiting': 3079,\n",
       " '‚ñÅconsider': 1528,\n",
       " 'a\\\\tb\\\\n': 25010,\n",
       " '‚ñÅsometimes': 1847,\n",
       " '‚ñÅs_parola': 25178,\n",
       " '‚ñÅdependencies': 3854,\n",
       " '‚ñÅi<1000;': 22115,\n",
       " 'Ensure': 23433,\n",
       " 'while(true)': 14663,\n",
       " '‚ñÅthis:\\n\\n```\\nfor': 11845,\n",
       " '‚ñÅstd::cout': 6030,\n",
       " 'makefile': 9350,\n",
       " '\\nEDIT': 13877,\n",
       " 'explore': 15265,\n",
       " '-time': 7897,\n",
       " '‚ñÅ/2015/Date*': 28244,\n",
       " \"'%u'\": 20621,\n",
       " \":\\\\n');\\n\": 6020,\n",
       " '‚ñÅowner': 11859,\n",
       " 'intand': 6580,\n",
       " '‚ñÅrepresent': 1381,\n",
       " '‚ñÅPi': 11047,\n",
       " 'like\\n\\n```\\nstruct': 18715,\n",
       " 'face[IF_NAMESIZE': 28981,\n",
       " '‚ñÅ@': 1542,\n",
       " '(0);\\n}\\n```\\n\\nI': 21576,\n",
       " '\\n```\\n\\nor\\n\\n```\\n': 6571,\n",
       " 'btn': 20205,\n",
       " '.gcda': 20849,\n",
       " '‚ñÅ10.9': 19028,\n",
       " '_Thread_local': 21291,\n",
       " '}\\n\\nif': 17564,\n",
       " 'nr_of_strings': 21304,\n",
       " '‚ñÅfp);\\n': 8490,\n",
       " 'lement': 17424,\n",
       " '‚ñÅLabVIEW': 24756,\n",
       " 'DR': 10435,\n",
       " '-26843545': 28016,\n",
       " '‚ñÅorigin': 10748,\n",
       " 'trcmp(str1,str2)': 23969,\n",
       " ':\\n\\n```\\nint*': 9379,\n",
       " \".dll')]\\n\": 23952,\n",
       " 'msys': 17129,\n",
       " '‚ñÅaspects': 17392,\n",
       " '<cstring>': 21849,\n",
       " 'iteration': 21117,\n",
       " \"‚ñÅ'';\\n\": 12962,\n",
       " '‚ñÅexpressions': 1880,\n",
       " '‚ñÅassert(': 8514,\n",
       " 'wordlist': 20207,\n",
       " 'speed': 11196,\n",
       " '‚ñÅlocate': 6781,\n",
       " \"‚ñÅ'cat'\": 19723,\n",
       " '-llibpython2.7': 23905,\n",
       " '‚ñÅ128': 3152,\n",
       " '‚ñÅtiny': 11796,\n",
       " 'getrusage': 19626,\n",
       " '*(p+': 17130,\n",
       " 'git.kernel.org/': 21739,\n",
       " '(v=VS.85).aspx': 28359,\n",
       " \"printf('%c',\": 4307,\n",
       " '‚ñÅ*(': 3143,\n",
       " 'semicolon': 25031,\n",
       " '#pragma': 2175,\n",
       " '‚ñÅAPIs': 3302,\n",
       " '\\n\\nnow': 19078,\n",
       " \"‚ñÅ'12\": 13603,\n",
       " ',0xFD,0x6E,0x2D}': 23722,\n",
       " '‚ñÅfor(i=0;i<': 6324,\n",
       " '‚ñÅfunc': 2199,\n",
       " '\\ndouble': 9510,\n",
       " 'BE': 10568,\n",
       " 'C17': 19422,\n",
       " '[-1]': 12765,\n",
       " '‚ñÅ1)': 815,\n",
       " '(-1)': 10719,\n",
       " 'DL': 12033,\n",
       " '‚ñÅ(!fork())': 22946,\n",
       " 'john': 13201,\n",
       " '0or1': 13257,\n",
       " '‚ñÅcont': 7391,\n",
       " '/proc/uptime': 21785,\n",
       " 'C#': 11116,\n",
       " '\\n\\nIt': 3033,\n",
       " ':\\n\\n1': 11741,\n",
       " 'pointer,': 9137,\n",
       " 'GetSystemMetrics': 25728,\n",
       " '‚ñÅ(at': 4778,\n",
       " '‚ñÅSIGSEGV': 10626,\n",
       " '\\n\\n```\\nsscanf(': 16426,\n",
       " 'FTP': 9500,\n",
       " 'wcscmp': 19218,\n",
       " 'setrlimit': 16598,\n",
       " 'ptr': 803,\n",
       " 'PTHREAD_MUTEX_': 17965,\n",
       " 'DF': 4988,\n",
       " 'fin': 5276,\n",
       " 'local': 3000,\n",
       " 'address-of': 17679,\n",
       " 'ru': 5631,\n",
       " '‚ñÅboth': 294,\n",
       " '\\n//': 1030,\n",
       " \"scanf('%d',&a[i]\": 20639,\n",
       " 'pointer_to_T->s': 23211,\n",
       " '++;\\n```\\n': 11610,\n",
       " 'non-modifiable': 18878,\n",
       " 'tagPOINT': 21458,\n",
       " '‚ñÅOverflow': 1428,\n",
       " ',0,0,': 11954,\n",
       " 'UI': 8022,\n",
       " '‚ñÅconstrain': 18350,\n",
       " 'NO': 5156,\n",
       " '\\nusing': 10078,\n",
       " '‚ñÅsurname': 20465,\n",
       " 'having': 10823,\n",
       " '‚ñÅcentral': 18897,\n",
       " 'execve(': 15688,\n",
       " '‚ñÅroll': 8464,\n",
       " ':\\n\\nOn': 17548,\n",
       " \"‚ñÅ'file\": 11350,\n",
       " '$(NAME)': 21452,\n",
       " 'new->model': 24864,\n",
       " '‚ñÅ\\nYour': 1236,\n",
       " \"%i\\\\n',\": 16749,\n",
       " '\\n\\nYou': 2237,\n",
       " '‚ñÅassemble': 16520,\n",
       " \"‚ñÅAPI's\": 16454,\n",
       " 'qcpg': 23432,\n",
       " 'Collect': 16563,\n",
       " 'AP': 8909,\n",
       " 'ross': 12709,\n",
       " '<identifier>': 23461,\n",
       " 'clibrary/cstdio/': 25070,\n",
       " '‚ñÅshorten': 13946,\n",
       " 'DPRINTF(': 20862,\n",
       " '\\nplease': 8997,\n",
       " '‚ñÅargvababab': 27991,\n",
       " 'emphasis': 10109,\n",
       " 'objc_': 21948,\n",
       " '‚ñÅreadable': 2615,\n",
       " 'assigned': 14226,\n",
       " '\\n\\nSuppose': 16506,\n",
       " '‚ñÅimpact': 13902,\n",
       " '‚ñÅkindly': 9385,\n",
       " '(a-b)': 19386,\n",
       " '‚ñÅniftest.': 24967,\n",
       " 'start_time': 16050,\n",
       " '‚ñÅmingw': 8600,\n",
       " '--69447:1:': 26027,\n",
       " '‚ñÅblack': 9012,\n",
       " 'citizen': 22288,\n",
       " '\\n\\n```\\nshort': 19045,\n",
       " '*(a': 5509,\n",
       " 'sum2=((p%m)*(((': 29567,\n",
       " 'handle': 4879,\n",
       " 'pc1.p': 22399,\n",
       " '‚ñÅHAL_UART_': 23271,\n",
       " '≈Ç': 29736,\n",
       " 'uniq': 21529,\n",
       " 'standing': 17469,\n",
       " '‚ñÅofx': 9739,\n",
       " '-with-': 9899,\n",
       " '‚ñÅgdb.': 12848,\n",
       " \"‚ñÅ%i\\\\n',\": 9308,\n",
       " 'uck': 11218,\n",
       " '‚ñÅISEQUAL(': 25181,\n",
       " \"'/dev/accel'\": 22223,\n",
       " 'PATH=/usr/local/': 25585,\n",
       " 'gdb-multiarch': 25918,\n",
       " 'Assignment': 13915,\n",
       " '‚ñÅplace.\\n': 13294,\n",
       " 'hy': 12039,\n",
       " 'https://elixir.': 27837,\n",
       " '‚ñÅ0);': 11185,\n",
       " 'tic-tac-toe': 29346,\n",
       " '‚ñÅfilesystem': 3489,\n",
       " 'mgrs_to_utm': 28976,\n",
       " \"‚ñÅ*ign_st='O\": 25867,\n",
       " '‚ñÅnamespace': 3327,\n",
       " '_ctx': 14515,\n",
       " 'pragma': 15393,\n",
       " '‚ñÅwebsites': 14852,\n",
       " '‚ñÅ#2': 15033,\n",
       " \"‚ñÅW\\\\0ORLD!';\\n\": 27591,\n",
       " 'alloArray(': 26684,\n",
       " '};\\n```\\n\\nYou': 17959,\n",
       " '\\nwhen': 5076,\n",
       " '\\n\\nP.S': 15469,\n",
       " '‚îú': 25643,\n",
       " '.This': 3906,\n",
       " '9999': 15248,\n",
       " '‚ñÅonly': 105,\n",
       " '};\\n\\nint': 5870,\n",
       " '_print': 10729,\n",
       " '‚ñÅinsertion': 9664,\n",
       " 'buffer[0]': 9774,\n",
       " '‚ñÅPerson_messup(': 27630,\n",
       " 'print(': 6289,\n",
       " 'arp': 10582,\n",
       " 'dont': 17950,\n",
       " 'TimeoutUSecs;': 28087,\n",
       " 'abort()': 12139,\n",
       " 'wcstombs': 25244,\n",
       " '\\n\\nthen': 11712,\n",
       " '‚ñÅSYSCTL_': 26400,\n",
       " '\\nfor(i=0;i<': 17207,\n",
       " 'Platform': 6731,\n",
       " 'ft_strupcase(': 27903,\n",
       " '1st': 11606,\n",
       " '‚ñÅtemp': 728,\n",
       " 'Plugin': 19967,\n",
       " ').I': 14030,\n",
       " 'web': 7778,\n",
       " '/cstdio/printf/': 22602,\n",
       " '‚ñÅposix': 10857,\n",
       " '‚ñÅ4)\\n': 15103,\n",
       " 'settings': 13068,\n",
       " '.\\n\\nJust': 5349,\n",
       " '‚ñÅmet': 7362,\n",
       " 'OULD': 22841,\n",
       " '‚ñÅ(percent': 22803,\n",
       " 'uc': 3442,\n",
       " '‚ñÅdealing': 4839,\n",
       " '‚ñÅ};\\n': 2585,\n",
       " '11': 1197,\n",
       " \"');\\n```\\n\": 3649,\n",
       " '‚ñÅanalyzing': 19186,\n",
       " '_fieldsY': 20437,\n",
       " '‚ñÅdifference.': 8914,\n",
       " '*c': 7733,\n",
       " '‚ñÅIN': 11406,\n",
       " '‚ñÅexists,': 9756,\n",
       " '‚ñÅtheoretical': 14170,\n",
       " 'LocalFree': 21419,\n",
       " '},\\n': 6128,\n",
       " ':\\n\\n```\\nunion': 18340,\n",
       " '‚ñÅinlining': 13217,\n",
       " '2i_RSAPrivateKey': 29438,\n",
       " '‚ñÅtry/catch': 21758,\n",
       " '‚ñÅresults.\\n': 11235,\n",
       " '‚ñÅreturns': 363,\n",
       " 'Tcl_Obj': 24773,\n",
       " '\\n\\nOn': 10726,\n",
       " '‚ñÅthese': 257,\n",
       " ';\\n```\\n\\nNow': 6694,\n",
       " '‚ñÅ(though': 12341,\n",
       " '‚ñÅGenerally': 17323,\n",
       " 'Answer': 12713,\n",
       " '‚ñÅP': 1485,\n",
       " 'uname': 12133,\n",
       " 'addition': 16601,\n",
       " '‚ñÅ0x8(%ebp)': 26262,\n",
       " '(in': 3250,\n",
       " '‚ñÅetc.\\n\\nI': 18722,\n",
       " '_task': 10832,\n",
       " '‚ñÅround': 3159,\n",
       " 'mbrtowc': 22703,\n",
       " '[b]': 15874,\n",
       " \"Hello.mp3','rb')\": 27956,\n",
       " '32.Parse(values[': 29417,\n",
       " 'CreateWindow': 10296,\n",
       " 'FRAME': 16251,\n",
       " '‚ñÅd;\\n': 5838,\n",
       " 'HelloWorld': 13969,\n",
       " '7F': 17347,\n",
       " '&tvhti.pt);\\nS': 29590,\n",
       " 'blockDim.x': 26239,\n",
       " '((char*)': 9764,\n",
       " '‚ñÅmicroprocessor': 20908,\n",
       " 'flipped': 21478,\n",
       " 'max%a': 23458,\n",
       " 'objdump': 6803,\n",
       " '‚ñÅhInstance,': 20872,\n",
       " '==1': 8074,\n",
       " '17,204,99,16};\\n\\n': 25127,\n",
       " 'vect': 16744,\n",
       " '0111': 6164,\n",
       " 'is_palindrome(': 25996,\n",
       " 'DIMENSIONS': 28225,\n",
       " '‚ñÅ1234': 8725,\n",
       " '‚ñÅfloating-point': 4092,\n",
       " 'price_of_diamond': 23246,\n",
       " \"‚ñÅ'pro2.pifz';\\n\": 25955,\n",
       " 'External': 19990,\n",
       " '‚ñÅdriver': 1982,\n",
       " '‚ñÅfile1.o': 20037,\n",
       " 'Inventory': 21744,\n",
       " '(along': 17467,\n",
       " 'Seconds': 10025,\n",
       " 'wolf': 22899,\n",
       " 'ms682073': 28701,\n",
       " '2,': 831,\n",
       " 'Flags': 9110,\n",
       " 'exclamation': 21736,\n",
       " '/Strings/': 23521,\n",
       " 'MY_PATTERN': 28381,\n",
       " 'Request': 10867,\n",
       " '.a,': 12266,\n",
       " 'decimal_places': 24659,\n",
       " 'Rtl': 11253,\n",
       " '‚ñÅspecified': 1050,\n",
       " '‚ñÅ*/\\nvoid': 13296,\n",
       " 'hello_': 13474,\n",
       " 'sizeof(st.magic)': 24821,\n",
       " 'global': 3882,\n",
       " 'amp': 5878,\n",
       " 'Database': 13938,\n",
       " 'preprocessing': 22627,\n",
       " '‚ñÅpermissible': 27028,\n",
       " '_saltBytes': 25334,\n",
       " '_and_': 11359,\n",
       " 'structure': 2983,\n",
       " '‚ñÅadvance\\n': 3861,\n",
       " 'PS': 4382,\n",
       " 'house': 17685,\n",
       " '‚ñÅMS': 5554,\n",
       " '‚ñÅC/C++': 714,\n",
       " '‚ñÅb=': 5934,\n",
       " 'i=1': 12642,\n",
       " 'messages': 15206,\n",
       " 'PRE': 13608,\n",
       " '‚ñÅ(on': 4022,\n",
       " '‚ñÅagent': 19294,\n",
       " '‚ñÅapparently': 4608,\n",
       " '√ò': 29714,\n",
       " '\\n```\\n\\nBoth': 20296,\n",
       " 'mu': 11806,\n",
       " '~/workspace/pset': 27808,\n",
       " 'bytes': 1752,\n",
       " 'thanks': 10805,\n",
       " '1is': 5844,\n",
       " 'Make': 5897,\n",
       " '‚ñÅtagged': 11475,\n",
       " 'float[crCount];\\n': 24471,\n",
       " 'lexicographical': 25296,\n",
       " '‚ñÅhard-cod': 23112,\n",
       " '(my': 4200,\n",
       " '‚ñÅstm.tm_': 21164,\n",
       " '‚ñÅsymbols': 1383,\n",
       " '‚ñÅvalues,': 3240,\n",
       " '‚ñÅWS_VISIBLE': 23724,\n",
       " 'count);\\n': 10754,\n",
       " '+4': 7084,\n",
       " '‚ñÅtip': 15518,\n",
       " '‚ñÅlock': 2565,\n",
       " 'dispatch_async': 24563,\n",
       " '/full/path/to/': 25447,\n",
       " '+----+': 18846,\n",
       " '‚ñÅpacket': 1782,\n",
       " \"\\nprintf('%d\": 11302,\n",
       " '‚ñÅconcurrent': 14676,\n",
       " '‚ñÅmeasure': 4098,\n",
       " '‚ñÅpracticing': 19557,\n",
       " '/C': 7276,\n",
       " '‚ñÅextract': 1593,\n",
       " \"'glob');\\nlua_get\": 28825,\n",
       " '5.1.2.2.1': 22217,\n",
       " '‚ñÅwas': 123,\n",
       " 'YSCALL(SYS_SEND,': 28950,\n",
       " 'les': 8394,\n",
       " '‚ñÅANSI-C': 16917,\n",
       " '‚ñÅwent': 5073,\n",
       " 'communicating': 20804,\n",
       " 'grad_phi_x': 25861,\n",
       " 'j++)\\n{\\n': 20289,\n",
       " '‚ñÅpointing': 1386,\n",
       " '‚ñÅCUDA_MALLOC(': 28598,\n",
       " 'morning.c': 22581,\n",
       " '‚ñÅexec': 4263,\n",
       " 'look': 10322,\n",
       " 'crawler': 20438,\n",
       " '‚ñÅterminator.': 14134,\n",
       " '‚ñÅcodeblocks': 10007,\n",
       " '_int': 3104,\n",
       " 'Debugger': 12756,\n",
       " '%*s': 10614,\n",
       " 'hworks.com/help/': 26118,\n",
       " '‚ñÅdistributions': 15711,\n",
       " 'MQStructObj[': 28695,\n",
       " 'random()': 19319,\n",
       " '‚ñÅscaling': 17637,\n",
       " '-compiler': 16748,\n",
       " 'python2.7': 17675,\n",
       " '‚ñÅ+\\n<A,W,Z': 27534,\n",
       " '(array)': 9506,\n",
       " '‚ñÅ<fstream>\\n': 22846,\n",
       " '‚ñÅtypesize_t': 15771,\n",
       " 'gr': 3724,\n",
       " 'Dummy': 16525,\n",
       " 'log10': 16052,\n",
       " '-faq.com/aryptr/': 22802,\n",
       " '‚ñÅway:\\n\\n```\\n': 9709,\n",
       " 'Gives': 14508,\n",
       " '‚ñÅget:\\n\\n```\\n': 9322,\n",
       " \"Here's\": 2329,\n",
       " 'resolv': 10893,\n",
       " 'Live': 18523,\n",
       " 'useconds_t': 24832,\n",
       " '‚ñÅCodeBlocks': 10678,\n",
       " '0x30': 9616,\n",
       " '‚ñÅ\\nPer': 16469,\n",
       " '_ELEM(': 25316,\n",
       " \"]',f1,f1,f1);\": 25736,\n",
       " '‚ñÅlexical': 14068,\n",
       " '(1,': 4338,\n",
       " '‚ñÅconsidered': 1833,\n",
       " '‚ñÅshader': 12988,\n",
       " 'gender': 14756,\n",
       " 'LPSTR': 20022,\n",
       " '‚ñÅfamous': 18797,\n",
       " '‚ñÅlanguages': 1721,\n",
       " \"‚ñÅ'abc\": 13188,\n",
       " '\\n}\\n```\\n\\nI': 3478,\n",
       " '\\n\\nUse': 13403,\n",
       " 'decode': 17568,\n",
       " ',sum=0,': 23506,\n",
       " 'demonstrat': 25614,\n",
       " 'options': 4783,\n",
       " 'compatibility': 21128,\n",
       " 'Training': 20412,\n",
       " '‚ñÅrunning,': 12120,\n",
       " 'uint64_t': 3890,\n",
       " '_WIN64': 22235,\n",
       " '‚ñÅintrinsic': 10076,\n",
       " '‚ñÅhidden': 5414,\n",
       " '‚ñÅlocated': 2839,\n",
       " '_DIGEST_LENGTH': 27098,\n",
       " 'PU_ZERO(&mask);\\n': 28800,\n",
       " '‚ñÅterminated.': 8144,\n",
       " '‚ñÅi;\\n': 824,\n",
       " '‚ñÅ(*korzen)->': 24567,\n",
       " '/sys/bus/': 23873,\n",
       " '‚ñÅmaintain': 4972,\n",
       " 'libpng': 13700,\n",
       " '‚ñÅsolve': 845,\n",
       " 'Color': 4828,\n",
       " '(0);\\n': 11961,\n",
       " 'ame[strlen(name)': 26689,\n",
       " '‚ñÅparameters,': 10229,\n",
       " '‚ñÅgeneric': 3142,\n",
       " '{1,2}': 14209,\n",
       " 'fork(2)': 20118,\n",
       " 'Channel': 16538,\n",
       " '‚ñÅspeciÔ¨Åcation': 25668,\n",
       " 'Do': 2680,\n",
       " 'Files': 10688,\n",
       " '6589883863925934': 29618,\n",
       " 'http': 9193,\n",
       " '```\\n\\nIt': 15551,\n",
       " '‚ñÅlibxml2': 10009,\n",
       " 'ModuleFileName(': 24221,\n",
       " 'SP': 6705,\n",
       " '‚ñÅ&estructura': 25920,\n",
       " 'item': 3241,\n",
       " '_bytes(': 17144,\n",
       " '‚ñÅspeaking,': 12620,\n",
       " '‚ñÅ0xf': 8634,\n",
       " ').\\n\\nIf': 5664,\n",
       " '‚ñÅreconstruct': 21461,\n",
       " 'TO': 6750,\n",
       " \"printf('\\\\n%d',\": 17877,\n",
       " 'CUSTOM': 22251,\n",
       " 'g_main_loop_new': 27655,\n",
       " '‚ñÅwebsite': 4993,\n",
       " '‚ñÅtrue,': 4021,\n",
       " \"E:\\\\\\\\temp\\\\\\\\1.txt'\": 27531,\n",
       " '‚ñÅtrailing': 3566,\n",
       " '‚ñÅManipulation': 28062,\n",
       " '\\\\s)|(?<=': 24668,\n",
       " 'intvalue': 13392,\n",
       " '‚ñÅgracefully': 17980,\n",
       " 'generates': 16380,\n",
       " 'CallObjectMethod': 25368,\n",
       " '‚ñÅlanguage?': 12418,\n",
       " '‚ñÅclarity.': 1550,\n",
       " 'MapViewOfFile': 22690,\n",
       " '\\\\n': 990,\n",
       " '‚ñÅrows': 3156,\n",
       " '‚ñÅi,j,': 10800,\n",
       " '‚ñÅsolutions': 2801,\n",
       " \"\\\\n');\\n}\\n\\n\": 17126,\n",
       " '‚ñÅ$(BINDIR)/': 25766,\n",
       " 'n-us/library/dd3': 27314,\n",
       " \"pqrstuvwxyz'[m];\": 26671,\n",
       " 'PyRun_Simple': 22695,\n",
       " '(errno': 18060,\n",
       " 'Layer': 12986,\n",
       " 'gettimeofday()': 18109,\n",
       " '\\n\\nWhat': 2064,\n",
       " '‚ñÅtargets': 6154,\n",
       " '‚ñÅglance': 21904,\n",
       " '‚ñÅ.x=10}': 24619,\n",
       " 'person': 6471,\n",
       " 'O72049366_ONCE\\n#': 28200,\n",
       " 'strrchr()': 19476,\n",
       " '‚ñÅConsider': 9232,\n",
       " 'POS': 19141,\n",
       " '!%2!s!%3!s!\\\\': 29509,\n",
       " '...)\\n': 9361,\n",
       " '‚ñÅcollect': 10253,\n",
       " 'uint8_t': 2125,\n",
       " 'reinterpret': 17140,\n",
       " '‚ñÅbuild': 558,\n",
       " '208': 14828,\n",
       " 'chas': 13397,\n",
       " 'ran': 5743,\n",
       " 'tf': 10267,\n",
       " '‚ñÅpossibly': 1765,\n",
       " '‚ñÅubiquitous': 25790,\n",
       " '‚ñÅsizeof(struct': 7345,\n",
       " '‚ñÅdocumented': 4180,\n",
       " 'school': 22624,\n",
       " '(bar)': 18600,\n",
       " 'tr,10);\\nalcd_put': 28045,\n",
       " '0:07:80:4C:0E:EE': 29507,\n",
       " '‚ñÅaltogether': 15289,\n",
       " '‚ñÅpointer.': 1652,\n",
       " 'n,': 5268,\n",
       " 'operating': 20197,\n",
       " 'constexpr': 19785,\n",
       " 'Spotify': 24700,\n",
       " '‚ñÅsystem.': 3054,\n",
       " \"'999999999999'\": 26519,\n",
       " 'hist': 20263,\n",
       " 'isspace': 8988,\n",
       " 'mpf_t': 19296,\n",
       " '‚ñÅmean?': 3790,\n",
       " '‚ñÅthe%operator': 21915,\n",
       " 'recursion': 21635,\n",
       " '\\n```\\n\\nyou': 13568,\n",
       " '‚ñÅ<<': 386,\n",
       " '‚ñÅcaught': 12101,\n",
       " '‚ñÅescalunador': 25634,\n",
       " '‚ñÅunderflow': 17318,\n",
       " 'WS_OVERLAPPED': 20417,\n",
       " '√ß': 15565,\n",
       " 'UB': 11950,\n",
       " 'MTU,': 24242,\n",
       " '(y-8)/9*3': 29190,\n",
       " '‚ñÅoutput.': 2967,\n",
       " '‚ñÅIMMEDIATE': 27626,\n",
       " '((__packed__))': 19551,\n",
       " '...)': 3582,\n",
       " '‚ñÅwatch': 4602,\n",
       " '‚ñÅsuitable': 4317,\n",
       " 'Alt': 20274,\n",
       " '‚ñÅ(b)': 11868,\n",
       " '\\n\\n```\\n#': 7323,\n",
       " '‚ñÅsaid': 1676,\n",
       " 'LinkedList': 15026,\n",
       " '‚ñÅexpanded': 4400,\n",
       " ';}': 9733,\n",
       " 'Frame': 5256,\n",
       " '‚ñÅ(*(': 11292,\n",
       " '‚ñÅpredicate': 17960,\n",
       " \"'test'\": 14594,\n",
       " 'HASH_CONS_EQUAL': 25676,\n",
       " \"%02i:%02i',\": 29356,\n",
       " '(1,2)': 13822,\n",
       " \"!';\\n\": 14452,\n",
       " 'inet': 8862,\n",
       " '‚ñÅ(including': 5103,\n",
       " '‚ñÅsemantics': 6530,\n",
       " '[10];\\n```\\n\\n': 17134,\n",
       " '‚ñÅoperation': 938,\n",
       " '+10': 10377,\n",
       " '\\u2029': 29980,\n",
       " 'UnixAssembler': 25772,\n",
       " 'MAX_TEAMS_AMOUNT': 28198,\n",
       " '[i]);\\n```\\n': 12681,\n",
       " '‚ñÅtypes.': 5572,\n",
       " 'verifie': 25088,\n",
       " 'luaVM': 22476,\n",
       " 'ert': 12386,\n",
       " 'SR': 9113,\n",
       " 'sitor->visitjob_': 29028,\n",
       " '‚ñÅTRANSACTION': 25740,\n",
       " '‚ñÅ(e.g': 16436,\n",
       " \"don't\": 5036,\n",
       " '‚ñÅother?\\n': 12221,\n",
       " 'openssl/sha.h': 23331,\n",
       " '(!feof(fop))': 28777,\n",
       " '‚ñÅsizeof(float));': 18566,\n",
       " '‚ñÅC99': 1012,\n",
       " 'DIA': 17487,\n",
       " '‚ñÅunlucky': 26227,\n",
       " 'Word': 5225,\n",
       " '!\\n': 837,\n",
       " 'Bubble': 24692,\n",
       " '‚ñÅoperands': 2924,\n",
       " '\\n\\n```\\n*(': 13842,\n",
       " 'Strange': 21921,\n",
       " 'Your': 4676,\n",
       " 'SECTION': 22726,\n",
       " 'implement': 15373,\n",
       " '‚ñÅY': 4131,\n",
       " \"‚ñÅprintw('\": 18848,\n",
       " '[5]={1,2,3,4,5};': 23938,\n",
       " 'open(2)': 17774,\n",
       " '0;': 6304,\n",
       " '‚ñÅ2.1': 13161,\n",
       " \"rsion='1.0'?>\\n<d\": 29593,\n",
       " '‚ñÅdecrement': 4931,\n",
       " '‚ñÅ(https://': 14380,\n",
       " '!=EOF)': 14345,\n",
       " '0\\n': 4336,\n",
       " \"[i]!='\\\\0';i++)\": 21155,\n",
       " '‚ñÅstyle': 1703,\n",
       " 'QconnectdbParams': 26707,\n",
       " 'ported': 19143,\n",
       " 'wait(&status)': 17266,\n",
       " '‚ñÅ99': 5224,\n",
       " '‚ñÅatoi(': 3683,\n",
       " ',Friday,Saturday': 28996,\n",
       " '‚ñÅdigital': 14764,\n",
       " \"'%d.%d.%d.%d',\": 22670,\n",
       " '/gmp-discuss/200': 25753,\n",
       " '‚ñÅsize)': 7122,\n",
       " '‚ñÅalgebra': 14423,\n",
       " '‚ñÅByte': 8667,\n",
       " \".txt'\": 3964,\n",
       " '‚ñÅstructure.': 5271,\n",
       " '$arg0': 20476,\n",
       " '‚ñÅhours': 5291,\n",
       " '‚ñÅ=': 16,\n",
       " 'swift': 19991,\n",
       " 'ls_tbs_fs': 27437,\n",
       " \"‚ñÅ'b'\": 4530,\n",
       " 'www.opengl.org/': 23295,\n",
       " '‚ñÅmax': 1000,\n",
       " \"'re\": 4850,\n",
       " 'Joueur': 25254,\n",
       " 'uadratic': 27346,\n",
       " 'realpath': 20154,\n",
       " 'td': 10931,\n",
       " 'UILabel': 22947,\n",
       " '‚ñÅ0x0F00F0F0\\n': 27631,\n",
       " '‚ñÅ0.0f': 14050,\n",
       " '?\\n\\nDoes': 8242,\n",
       " '\\n\\n```\\nswitch': 18603,\n",
       " \"‚ñÅ'\\\\0')\": 7370,\n",
       " 'tain': 10334,\n",
       " ');\\n```\\n\\nwhere': 8506,\n",
       " '^^^^^^^': 18877,\n",
       " \"printf('%s',\": 4331,\n",
       " 'dFinishLaunching': 27948,\n",
       " 'BUILD': 14692,\n",
       " ');\\n```\\n\\nwill': 10194,\n",
       " 'White': 17628,\n",
       " '‚ñÅerr/warning\\n': 26486,\n",
       " ',6,9,12,15,18};\\n': 29184,\n",
       " 'ipAddr': 21211,\n",
       " '‚ñÅportably': 14183,\n",
       " 'Model': 13985,\n",
       " 'generated': 13150,\n",
       " 'wrapper': 15859,\n",
       " 'widdl': 21408,\n",
       " 'Eugene': 19950,\n",
       " '\\n\\nPlease': 6790,\n",
       " '_XTAL_FREQ': 24351,\n",
       " '\\noutput:\\n\\n```\\n': 20236,\n",
       " 'Floating': 11778,\n",
       " '‚ñÅcoefficients': 17736,\n",
       " ':19:': 16355,\n",
       " '‚ñÅfor(;i<': 22029,\n",
       " ':\\n\\n```\\nfloat': 4593,\n",
       " '‚ñÅpresumably': 10280,\n",
       " '‚ñÅstrcat(time,': 23487,\n",
       " 'utter': 15505,\n",
       " 'egisterCallback(': 26739,\n",
       " 'greeting': 12978,\n",
       " '2,147,483,647': 19925,\n",
       " 'off-topic': 5300,\n",
       " '-and-': 6692,\n",
       " 'RegOpenKeyEx': 26968,\n",
       " '‚ñÅdifferences': 3446,\n",
       " '%.4f': 21043,\n",
       " '‚ñÅ<netdb.h>\\n': 24848,\n",
       " '‚ñÅend-of-file': 13900,\n",
       " '‚ñÅaliasing': 9234,\n",
       " 'unary': 19778,\n",
       " 'Busybox': 23259,\n",
       " 'Comparing': 25421,\n",
       " '‚ñÅfor-loop': 8584,\n",
       " 'CC': 2549,\n",
       " '‚ñÅcylinder': 23244,\n",
       " 'CERT': 18841,\n",
       " 'strerror': 10433,\n",
       " '‚ñÅc89': 17357,\n",
       " '‚ñÅdirectory.': 3919,\n",
       " 'Executable': 15277,\n",
       " '‚ñÅcalcul': 21640,\n",
       " '‚ñÅguarantees': 6147,\n",
       " 'leave': 15493,\n",
       " 'query': 6404,\n",
       " '‚ñÅdamage': 20855,\n",
       " 'pposed': 6018,\n",
       " '‚ñÅ(x86_64)': 22509,\n",
       " 'nnel_data->pty_': 28664,\n",
       " '‚ñÅcrap': 20958,\n",
       " '‚ñÅ--c-kinds=': 24401,\n",
       " '‚ñÅredirected': 13043,\n",
       " '_OF_IDENTIFIER(': 29661,\n",
       " 'Fd': 15483,\n",
       " '‚ñÅdid': 604,\n",
       " '|S_IRWXG|S_IRWXO': 28946,\n",
       " 'c-icap': 22339,\n",
       " 'argv[argc-1]': 19938,\n",
       " 'Questions': 4346,\n",
       " '‚ñÅerrors.\\n': 8454,\n",
       " '‚ñÅ<stdarg.h>\\n': 16458,\n",
       " 'strtol(argv[1]': 25018,\n",
       " '‚ñÅstdio.h': 10159,\n",
       " '‚ñÅdetached': 16258,\n",
       " 'g_main_loop_run': 26091,\n",
       " '‚ñÅ(d': 8046,\n",
       " \"%.2lf',\": 22429,\n",
       " '‚ñÅscience': 20897,\n",
       " '587': 15058,\n",
       " '‚ñÅpad': 7958,\n",
       " 'putc(': 13166,\n",
       " 'example\\n\\n```\\nint': 22594,\n",
       " 'perl': 13385,\n",
       " 'include/': 8012,\n",
       " 'pprod': 21436,\n",
       " '‚ñÅpid': 2213,\n",
       " '‚ñÅexternal': 1434,\n",
       " \"'C'\": 13578,\n",
       " '‚ñÅguessing': 5212,\n",
       " 'Thread': 2923,\n",
       " 'lot': 15540,\n",
       " 'GA': 12182,\n",
       " 'gid': 9777,\n",
       " '‚ñÅ(*f)(': 17766,\n",
       " 'Bundle': 19596,\n",
       " 'php_': 19145,\n",
       " 'Ruby': 14857,\n",
       " 'project': 3679,\n",
       " 'System.out.print': 25076,\n",
       " \"‚ñÅ'class'\": 17316,\n",
       " 'File_Descriptor': 24778,\n",
       " 'price': 9796,\n",
       " '\\n\\nWell,': 19053,\n",
       " '‚ñÅsemget(': 22426,\n",
       " '->len': 15180,\n",
       " 'strncpy(': 4320,\n",
       " '\\nthanks': 14133,\n",
       " '‚ñÅadapter': 19337,\n",
       " '1+': 9546,\n",
       " '‚ñÅclean': 3130,\n",
       " 'fwrite': 4961,\n",
       " '\\n```\\n\\nor': 6176,\n",
       " 'lua_getfield(': 25112,\n",
       " '(gcc)': 17946,\n",
       " 'Clarification': 20861,\n",
       " '‚ñÅcatching': 17782,\n",
       " '‚ñÅperfectly': 1963,\n",
       " 's/imgproc/src/': 27971,\n",
       " '‚ñÅnibbles': 18129,\n",
       " 'Deployment': 27776,\n",
       " '\\nint': 506,\n",
       " '568': 19529,\n",
       " '‚ñÅm': 918,\n",
       " '__actionType': 24762,\n",
       " 'mainfunction': 8338,\n",
       " '‚ñÅCMake': 6440,\n",
       " '‚ñÅpersonally': 9496,\n",
       " 'MASK_THIRD;\\n}': 28846,\n",
       " 'boost::asio': 24672,\n",
       " 'elegant': 22626,\n",
       " '‚ñÅscreen.': 7077,\n",
       " 'ev': 5973,\n",
       " 'OD': 10648,\n",
       " '‚ñÅmkd_': 24921,\n",
       " 'Declare': 8905,\n",
       " 'copies': 16656,\n",
       " 'Picture.biWidth': 26064,\n",
       " '*=': 12186,\n",
       " 'isatty': 13910,\n",
       " '‚ñÅskip': 2921,\n",
       " 'arg1,': 10257,\n",
       " 'ppid': 13581,\n",
       " '‚ñÅheight': 2614,\n",
       " 'tModel_capacitor': 18765,\n",
       " '‚ñÅ*temp': 4284,\n",
       " \"\\\\t%2.2f',matr[i]\": 29210,\n",
       " 'Î†•': 27071,\n",
       " 'b>DATA</nodeb': 29336,\n",
       " '‚ñÅeasier': 1671,\n",
       " 'listen': 14849,\n",
       " 'advance': 23068,\n",
       " ...}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d555d6e",
   "metadata": {},
   "source": [
    "### Saving and Sharing Your Tokenizer\n",
    "\n",
    "Once your tokenizer is trained, you can save it locally for future use or push it to the Hugging Face Hub to share with others. This makes it easy to reload your tokenizer or use it in other projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c1d650c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('toks/llama3-stackoverflow/tokenizer_config.json',\n",
       " 'toks/llama3-stackoverflow/special_tokens_map.json',\n",
       " 'toks/llama3-stackoverflow/tokenizer.json')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.save_pretrained(\"toks/llama3-stackoverflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f706f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"<YOUR HF TOKEN WITH WRITE PERMISSIONS>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7cebf70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/sinsankio/llama3-stackoverflow-QA-C-language-40k/commit/b10d0331d5146b43a24d475b71d88b0b74f89acd', commit_message='Upload tokenizer', commit_description='', oid='b10d0331d5146b43a24d475b71d88b0b74f89acd', pr_url=None, repo_url=RepoUrl('https://huggingface.co/sinsankio/llama3-stackoverflow-QA-C-language-40k', endpoint='https://huggingface.co', repo_type='model', repo_id='sinsankio/llama3-stackoverflow-QA-C-language-40k'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.push_to_hub(\"llama3-stackoverflow-QA-C-language-40k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfd0f25",
   "metadata": {},
   "source": [
    "### Building a Tokenizer from Scratch\n",
    "\n",
    "If you want full control over the tokenization process, you can build a tokenizer step by step using the Tokenizers library. This lets you choose the normalization, pre-tokenization, model type, post-processing, and decoding methods that best fit your data and use case.\n",
    "\n",
    "Below, we show how to build WordPiece, BPE, and Unigram tokenizers, similar to those used in BERT, GPT-2, and Albert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f09020",
   "metadata": {},
   "source": [
    "#### Steps to Build a Tokenizer Pipeline\n",
    "\n",
    "A tokenizer pipeline usually includes:\n",
    "- **Normalization**: Clean and standardize text (e.g., lowercasing, removing accents).\n",
    "- **Pre-tokenization**: Split text into words or subwords.\n",
    "- **Model**: Learn subword units from your data.\n",
    "- **Post-processing**: Add special tokens for model compatibility.\n",
    "- **Decoding**: Convert tokens back to text.\n",
    "\n",
    "You can mix and match these steps to create a tokenizer that fits your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2f353adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import decoders, models, normalizers, pre_tokenizers, processors, trainers, Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(models.WordPiece(unk_token=\"[UNK]\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f4c69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.normalizer = normalizers.BertNormalizer(clean_text=True, strip_accents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "64801b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dbf20f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', (0, 4)),\n",
       " ('is', (5, 7)),\n",
       " ('a', (8, 9)),\n",
       " ('demo', (10, 14)),\n",
       " ('string', (15, 21)),\n",
       " ('copied', (22, 28)),\n",
       " ('from', (29, 33)),\n",
       " ('stackoverflow', (34, 47)),\n",
       " ('!', (47, 48)),\n",
       " ('üòä', (49, 50))]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pre_tokenizer.pre_tokenize_str('This is a demo string copied from stackoverflow! üòä')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2bb95a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = ['[UNK]', '[PAD]', '[CLS]', '[SEP]', '[MASK]']\n",
    "trainer = trainers.WordPieceTrainer(vocab_size=30_000, special_tokens=special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1b7d31d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.train_from_iterator(batch_generator(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fe93e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_batch([\"Hello, y'all! How are you üòÅ ?\", 'Huggingface made it easy!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "23c9ac59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', ',', 'y', \"'\", 'all', '!', 'how', 'are', 'you', '[UNK]', '?']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding[0].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "10cb87a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hug', '##ging', '##face', 'made', 'it', 'easy', '!']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding[1].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8a5ae034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 3\n"
     ]
    }
   ],
   "source": [
    "cls_token_id = tokenizer.token_to_id('[CLS]')\n",
    "sep_token_id = tokenizer.token_to_id('[SEP]')   \n",
    "print(cls_token_id, sep_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eaf831e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=f\"[CLS]:0 $A:0 [SEP]:0\",\n",
    "    pair=f\"[CLS]:0 $A:0 [SEP]:0 $B:1 [SEP]:1\",\n",
    "    special_tokens=[\n",
    "        (\"[CLS]\", cls_token_id),\n",
    "        (\"[SEP]\", sep_token_id),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2e48bb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_batch([\"Hello, y'all! How are you üòÅ ?\", 'Huggingface made it easy!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "013f89cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'hello',\n",
       " ',',\n",
       " 'y',\n",
       " \"'\",\n",
       " 'all',\n",
       " '!',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " '[UNK]',\n",
       " '?',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding[0].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3aa8f42a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'hug', '##ging', '##face', 'made', 'it', 'easy', '!', '[SEP]']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding[1].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c6f83afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decoder = decoders.WordPiece(prefix=\"##\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f7ff1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "new_tokenizer = BertTokenizerFast(tokenizer_object=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "50e9d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = new_tokenizer.encode([\"Hello, y'all! How are you üòÅ ?\", 'Huggingface made it easy!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f910d0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1236, 16, 67, 11, 761, 5, 697, 721, 605, 0, 35, 3, 20288, 6501, 4816, 2207, 602, 2120, 5, 3]\n"
     ]
    }
   ],
   "source": [
    "print(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c23e867",
   "metadata": {},
   "source": [
    "### Byte-Pair Encoding (BPE) Tokenizer\n",
    "\n",
    "BPE is a popular tokenization algorithm used in models like GPT-2. It splits text into subword units based on the frequency of character pairs, allowing the tokenizer to handle rare words and misspellings more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "65d156a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(models.BPE())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7bebbdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fd10b847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('This', (0, 4)),\n",
       " ('ƒ†is', (4, 7)),\n",
       " ('ƒ†a', (7, 9)),\n",
       " ('ƒ†demo', (9, 14)),\n",
       " ('ƒ†string', (14, 21)),\n",
       " ('ƒ†copied', (21, 28)),\n",
       " ('ƒ†from', (28, 33)),\n",
       " ('ƒ†stackoverflow', (33, 47)),\n",
       " ('!', (47, 48)),\n",
       " ('ƒ†√∞≈Åƒ∫ƒ¨', (48, 50))]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pre_tokenizer.pre_tokenize_str('This is a demo string copied from stackoverflow! üòä')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b7970189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = trainers.BpeTrainer(vocab_size=30000, special_tokens=[\"<|endoftext|>\"])\n",
    "tokenizer.train_from_iterator(batch_generator(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f318096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.post_processor = processors.ByteLevel(trim_offsets=True)\n",
    "tokenizer.decoder = decoders.ByteLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0a217160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "new_tokenizer = GPT2TokenizerFast(tokenizer_object=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d043aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = new_tokenizer.encode([\"Hello, y'all! How are you üòÅ ?\", 'Huggingface made it easy!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2552b885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1664, 12, 251, 7, 353, 1, 894, 384, 264, 26360, 187, 164, 783, 40, 927, 2104, 2005, 2179, 252, 2380, 1]\n"
     ]
    }
   ],
   "source": [
    "print(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc49a24",
   "metadata": {},
   "source": [
    "### Unigram Tokenizer\n",
    "\n",
    "Unigram tokenization, used in models like Albert and T5, selects subword units based on their probability in the corpus. This approach can be more flexible and often works well for languages with complex word structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "896a152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(models.Unigram())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "483f12bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.normalizer = normalizers.Sequence(\n",
    "    [normalizers.Replace('''\"''', \"'\")]\n",
    ")\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Metaspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9c8936c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('‚ñÅThis', (0, 4)),\n",
       " ('‚ñÅis', (4, 7)),\n",
       " ('‚ñÅa', (7, 9)),\n",
       " ('‚ñÅdemo', (9, 14)),\n",
       " ('‚ñÅstring', (14, 21)),\n",
       " ('‚ñÅcopied', (21, 28)),\n",
       " ('‚ñÅfrom', (28, 33)),\n",
       " ('‚ñÅstackoverflow!', (33, 48)),\n",
       " ('‚ñÅüòä', (48, 50))]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pre_tokenizer.pre_tokenize_str(\"This is a demo string copied from stackoverflow! üòä\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "673e538c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer = trainers.UnigramTrainer(vocab_size=30000, special_tokens=[\"CLS\", \"[SEP]\", \"<unk>\", \"<pad>\", \"[MASK]\"], unk_token=\"<unk>\")\n",
    "tokenizer.train_from_iterator(batch_generator(), trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9649bd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    }
   ],
   "source": [
    "cls_token_id = tokenizer.token_to_id('CLS')\n",
    "sep_token_id = tokenizer.token_to_id('[SEP]')\n",
    "print(cls_token_id, sep_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "877a8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.post_processor = processors.TemplateProcessing(\n",
    "    single=\"[CLS]:0 $A:0 [SEP]:0\",\n",
    "    pair=\"[CLS]:0 $A:0 [SEP]:0 $B:1 [SEP]:1\",\n",
    "    special_tokens=[\n",
    "        (\"[CLS]\", cls_token_id),\n",
    "        (\"[SEP]\", sep_token_id),\n",
    "    ],\n",
    ")\n",
    "tokenizer.decoder = decoders.Metaspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f64f417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AlbertTokenizerFast\n",
    "\n",
    "new_tokenizer = AlbertTokenizerFast(tokenizer_object=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8a863370",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = new_tokenizer.encode([\"Hello, y'all! How are you üòÅ ?\", 'Huggingface made it easy!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3714285b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 6081, 9, 5, 152, 42, 1255, 434, 305, 41, 19, 5, 2, 5, 61, 1, 5, 15137, 13105, 12270, 869, 17, 1001, 434, 1]\n"
     ]
    }
   ],
   "source": [
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d952d41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"CLS Hello, y'all! How are you <unk> ?[SEP] Huggingface made it easy![SEP]\""
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.decode(encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4efb20",
   "metadata": {},
   "source": [
    "## Next Steps: Using Your Tokenizer\n",
    "\n",
    "Now that you have trained and saved your custom tokenizer, you can use it to train a language model from scratch or fine-tune an existing model. Just pass your tokenizer to the training scripts or notebooks, and your model will be able to process your domain-specific data more effectively.\n",
    "\n",
    "For more advanced usage, see the Hugging Face <a href='https://huggingface.co/docs/transformers/en/main_classes/tokenizer'>documentation</a> and examples for language modeling with custom tokenizers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e559d68",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
